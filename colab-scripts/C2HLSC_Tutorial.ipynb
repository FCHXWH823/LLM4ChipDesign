{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "91qy90OJ74Mk",
      "metadata": {
        "id": "91qy90OJ74Mk"
      },
      "source": [
        "# C2HLSC Tutorial – Leveraging LLMs to refactor C code into HLS‑compatible C\n",
        "\n",
        "**Goal:** Learn to use **C2HLSC** to transform ordinary C code into *High‑Level Synthesis (HLS)-amenable* C.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Set up the environment and clone the C2HLSC repo.\n",
        "2. Configure LLM API keys (OpenAI, Anthropic, and DeepSeek supported by the repo).\n",
        "3. Explore C2HLSC CLI options and run a hands‑on example (Cholesky decomposition).\n",
        "4. Inspect the transformed code and validate its correctness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wuenydz074Ml",
      "metadata": {
        "id": "wuenydz074Ml"
      },
      "source": [
        "## 0) Runtime check\n",
        "Quick sanity checks to confirm your local toolchain is available.\n",
        "\n",
        "This tutorial expects:\n",
        "\n",
        "- **Python 3.11+**\n",
        "\n",
        "- **gcc**, **g++**, **clang**, and **gdb**\n",
        "\n",
        "- Access to **Catapult HLS**\n",
        "\n",
        "If something is missing, install it or run on a machine where it's available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "runtime-check",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "runtime-check",
        "outputId": "0b5e827c-1247-43f6-e7b1-b252107997fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.11 (main, Jun 19 2025, 11:41:33) [GCC 8.5.0 20210514 (Red Hat 8.5.0-27)]\n",
            "Platform: Linux-4.18.0-553.70.1.el8_10.x86_64-x86_64-with-glibc2.28\n",
            "\n",
            "GCC version:\n",
            "gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-26)\n",
            "Copyright (C) 2018 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "\n",
            "G++ version:\n",
            "g++ (GCC) 8.5.0 20210514 (Red Hat 8.5.0-26)\n",
            "Copyright (C) 2018 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "\n",
            "Clang version:\n",
            "clang version 19.1.7 ( 19.1.7-2.module+el8.10.0+23045+e1f8e80e)\n",
            "Target: x86_64-redhat-linux-gnu\n",
            "Thread model: posix\n",
            "InstalledDir: /usr/bin\n",
            "Configuration file: /etc/clang/x86_64-redhat-linux-gnu-clang.cfg\n",
            "\n",
            "GDB version:\n",
            "GNU gdb (GDB) Red Hat Enterprise Linux 8.2-20.el8\n",
            "Copyright (C) 2018 Free Software Foundation, Inc.\n",
            "License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\n",
            "This is free software: you are free to change and redistribute it.\n",
            "There is NO WARRANTY, to the extent permitted by law.\n",
            "\n",
            "Catapult version:\n",
            "//  Catapult Ultra Synthesis 2023.1_2/1049935 (Production Release) Sat Jun 10 10:53:51 PDT 2023\n",
            "//  \n",
            "//          Copyright (c) Siemens EDA, 1996-2023, All Rights Reserved.\n",
            "//                        UNPUBLISHED, LICENSED SOFTWARE.\n",
            "//             CONFIDENTIAL AND PROPRIETARY INFORMATION WHICH IS THE\n",
            "//                   PROPERTY OF SIEMENS EDA OR ITS LICENSORS.\n",
            "//  \n",
            "//  Running on Linux ajh9498@hansolo.poly.edu 4.18.0-553.70.1.el8_10.x86_64 x86_64 aol\n",
            "//  \n",
            "//  Package information: SIFLIBS v26.1_2.0, HLS_PKGS v26.1_2.0, \n",
            "//                       SIF_TOOLKITS v26.1_2.0, SIF_XILINX v26.1_2.0, \n",
            "//                       SIF_ALTERA v26.1_2.0, CCS_LIBS v26.1_2.0, \n",
            "//                       CDS_PPRO v2022.1_1, CDS_DesigChecker v2023.1_1, \n",
            "//                       CDS_OASYS v21.1_3.1, CDS_PSR v22.2_0.9, \n",
            "//                       DesignPad v2.78_1.0\n",
            "//  \n"
          ]
        }
      ],
      "source": [
        "import platform, sys\n",
        "\n",
        "print('Python:', sys.version)\n",
        "\n",
        "print('Platform:', platform.platform())\n",
        "\n",
        "print('\\nGCC version:')\n",
        "!gcc --version || true\n",
        "\n",
        "print('\\nG++ version:')\n",
        "!g++ --version || true\n",
        "\n",
        "print('\\nClang version:')\n",
        "!clang --version || true\n",
        "\n",
        "print('\\nGDB version:')\n",
        "!gdb --version || true\n",
        "\n",
        "print('\\nCatapult version:')\n",
        "!catapult -version || true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6mD82Oxw74Mo",
      "metadata": {
        "id": "6mD82Oxw74Mo"
      },
      "source": [
        "## 1) Clone C2HLSC and install Python dependencies\n",
        "The repo expects Python 3.11+ and a few libraries. We'll install to the current environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "clone-install",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone-install",
        "outputId": "e194461d-fef0-48bf-c43d-b9122301c7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into './c2hlsc'...\n",
            "remote: Enumerating objects: 11389, done.\u001b[K\n",
            "remote: Counting objects: 100% (2626/2626), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1192/1192), done.\u001b[K\n",
            "remote: Total 11389 (delta 1596), reused 2402 (delta 1394), pack-reused 8763 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11389/11389), 167.50 MiB | 65.99 MiB/s, done.\n",
            "Resolving deltas: 100% (3771/3771), done.\n",
            "Updating files: 100% (13354/13354), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "REPO_URL = 'https://github.com/Lucaz97/c2hlsc'\n",
        "REPO_DIR = './c2hlsc'\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "\n",
        "!git clone $REPO_URL $REPO_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7922c8eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pycparser in /home/ajh9498/.local/lib/python3.12/site-packages (2.22)\n",
            "Requirement already satisfied: openai in /home/ajh9498/.local/lib/python3.12/site-packages (1.101.0)\n",
            "Requirement already satisfied: anthropic in /home/ajh9498/.local/lib/python3.12/site-packages (0.64.0)\n",
            "Requirement already satisfied: pyyaml in /home/ajh9498/.local/lib/python3.12/site-packages (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ajh9498/.local/lib/python3.12/site-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /home/ajh9498/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /home/ajh9498/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /home/ajh9498/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/ajh9498/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/ajh9498/.local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ajh9498/.local/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install Python deps expected by the repo\n",
        "\n",
        "%pip install pycparser openai anthropic pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad617bca",
      "metadata": {},
      "source": [
        "## 2) Switch into the C2HLSC repo\n",
        "\n",
        "From this point onward, all commands and scripts must be run inside the C2HLSC repository directory (`c2hlsc/`).\n",
        "\n",
        "Make sure you change into the repo root before continuing.\n",
        "\n",
        "If you restart the notebook later, you’ll need to re-run this cell to set the working directory correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "db0a03c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now working in: /home/ajh9498/Documents/C2HLSC_Tutorial/c2hlsc\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to repo directory (update if you cloned somewhere else)\n",
        "REPO_DIR = './c2hlsc'\n",
        "\n",
        "# Change into the repo\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print('Now working in:', os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y47wSCQD74Mo",
      "metadata": {
        "id": "y47wSCQD74Mo"
      },
      "source": [
        "## 3) Configure API keys (OpenAI, Anthropic, and/or DeepSeek)\n",
        "C2HLSC uses an LLM under the hood. Provide at least one key below. Keys are kept in this session only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "api-keys",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "api-keys",
        "outputId": "3cc96674-ea5d-425d-85f0-7c54bd3b3a68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API keys when prompted (input hidden). Press Enter to skip any.\n",
            "Keys set in environment: ['ANTHROPIC_API_KEY', 'DEEPSEEK_API_KEY', 'OPENAI_API_KEY']\n"
          ]
        }
      ],
      "source": [
        "import os, getpass\n",
        "\n",
        "print('Enter API keys when prompted (input hidden). Press Enter to skip any.')\n",
        "\n",
        "try:\n",
        "    k = getpass.getpass('OPENAI_API_KEY (optional): ')\n",
        "    if k.strip(): os.environ['OPENAI_API_KEY'] = k.strip()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    k = getpass.getpass('ANTHROPIC_API_KEY (optional): ')\n",
        "    if k.strip(): os.environ['ANTHROPIC_API_KEY'] = k.strip()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    k = getpass.getpass('DEEPSEEK_API_KEY (optional): ')\n",
        "    if k.strip(): os.environ['DEEPSEEK_API_KEY'] = k.strip()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print('Keys set in environment:', [k for k in os.environ if k in ('OPENAI_API_KEY','ANTHROPIC_API_KEY', 'DEEPSEEK_API_KEY')])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tzQrs41SXuza",
      "metadata": {
        "id": "tzQrs41SXuza"
      },
      "source": [
        "## 4) Explore the README and CLI help\n",
        "The README provides the input structure (includes, functions, test files) and the main entrypoint. Let's open the README and the CLI `-h` to see supported options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "show-readme-help",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "show-readme-help",
        "outputId": "1fe3e830-0093-4e5b-c7e5-de3dc0fe6787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# c2hlsc: A framework for automatically refactoring C code into synthesizable C code\n",
            "\n",
            "### Requirements\n",
            "The current version of the framework uses Catapult HLS. \n",
            "The framework uses gcc, g++ and gdb.\n",
            "\n",
            "Python dependencies:\n",
            "\n",
            "    python3.11 -m pip install pycparser openai anthropic pyyaml\n",
            "\n",
            "An API key for the model in use is needed.\n",
            "It can be set as an environment variable (ANTHROPIC_API_KEY, OPENAI_API_KEY, DEEPSEEK_API_KEY)\n",
            "\n",
            "### Input Structure\n",
            "The C/C++ code should be split into 3 files:\n",
            "\n",
            " - includes file: should contain the include libraries  and global variables that should not be refactored. We explicitly prompr the LLM to assume that the content of this file will be provided and should not be produced by the LLM.\n",
            " - functions file: should contain all and only  the functions that the LLM should refactor.\n",
            " - test file: should contain a main function with one or more tests, the results should be printed to stdout.\n",
            "\n",
            "One yaml file contains information about top function, file paths, type of interface (streaming or nor) and whether the code is hierarchical or not. \n",
            "\n",
            "###  Using c2hlsc:\n",
            "To run one of our benchmarks:\n",
            "\n",
            "    python3.11 src/c2hlsc.py inputs/${benchmark}/config_${benchmark}.yaml --model <model name> --opt_target <area/latency>\n",
            "\n",
            "To get a list of the possible models and other options: \n",
            "\n",
            "    python3.11 src/c2hlsc.py -h \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show README snippet\n",
        "\n",
        "!cat README.md || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "-QugURmcGeyg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QugURmcGeyg",
        "outputId": "418206b6-873c-480b-e6a5-d891b4e51f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: c2hlsc.py [-h]\n",
            "                 [--model {hyperbolic-reasoner,hyperbolic-chat,deepseek-ai/DeepSeek-R1,deepseek-ai/DeepSeek-V3,claude-3-5-sonnet-20240620,claude-3-5-haiku-20241022,gpt-4o-mini,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-0125,gpt-4o,adaptive,o3-mini,deepseek-chat,deepseek-reasoner}]\n",
            "                 [--opt_target {throughput,latency}]\n",
            "                 [--characterize CHARACTERIZE] [--opt_runs OPT_RUNS]\n",
            "                 [--from_saved FROM_SAVED]\n",
            "                 config\n",
            "\n",
            "C2HLSC script, yaml config required\n",
            "\n",
            "positional arguments:\n",
            "  config                yaml config file with the following fields: orig_code,\n",
            "                        test_code, includes, tcl, top_function\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model {hyperbolic-reasoner,hyperbolic-chat,deepseek-ai/DeepSeek-R1,deepseek-ai/DeepSeek-V3,claude-3-5-sonnet-20240620,claude-3-5-haiku-20241022,gpt-4o-mini,gpt-4-turbo-2024-04-09,gpt-3.5-turbo-0125,gpt-4o,adaptive,o3-mini,deepseek-chat,deepseek-reasoner}\n",
            "                        model name to use, default is adaptive\n",
            "  --opt_target {throughput,latency}\n",
            "                        optimization target, default is latency, options are:\n",
            "                        throughput, latency\n",
            "  --characterize CHARACTERIZE\n",
            "                        using this option will run the benchmark\n",
            "                        characterization\n",
            "  --opt_runs OPT_RUNS   Number of optimization runs, default is 1\n",
            "  --from_saved FROM_SAVED\n",
            "                        pickle file to load cfg from\n"
          ]
        }
      ],
      "source": [
        "# Show CLI help\n",
        "\n",
        "!python3.11 src/c2hlsc.py -h || true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jOywHBM574Mq",
      "metadata": {
        "id": "jOywHBM574Mq"
      },
      "source": [
        "## 5) Create a hands‑on example: Cholesky decomposition\n",
        "We'll prepare a minimal input folder under `inputs/cholesky_demo/` with:\n",
        "\n",
        "- `includes.h` – system includes and any global constants not to be refactored\n",
        "\n",
        "- `functions.c` – **the code to refactor/optimize**\n",
        "\n",
        "- `test.c` – a `main()` function that compiles/runs in software to check functional correctness\n",
        "\n",
        "- `config_cholesky_demo.yaml` – tells C2HLSC where files live and what to transform\n",
        "\n",
        "Then we'll run C2HLSC with your chosen model and an optimization target (`latency` or `throughput`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "28df1e73",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "879"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split code into includes, functions, and test files\n",
        "\n",
        "import textwrap, pathlib\n",
        "base = pathlib.Path('inputs/cholesky_demo')\n",
        "base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "(base / 'includes.h').write_text(textwrap.dedent('''\\\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#ifndef N\n",
        "#define N 3\n",
        "#endif\n",
        "\n",
        "#ifndef TYPE_T\n",
        "#define TYPE_T int\n",
        "#endif\n",
        "typedef TYPE_T type_t;\n",
        "\n",
        "void cholesky(type_t A[N][N], type_t L[N][N], type_t D[N][N]);\n",
        "\n",
        "\n",
        "'''))\n",
        "\n",
        "\n",
        "(base / 'functions.cpp').write_text(textwrap.dedent('''\\\n",
        "\n",
        "\n",
        "void cholesky(type_t A[N][N], type_t L[N][N], type_t D[N][N]) {\n",
        "    \n",
        "    for (int i = 0; i < N; i++) {\n",
        "\n",
        "        for (int j = 0; j <= i; j++) {\n",
        "\n",
        "            type_t sum = 0;\n",
        "            for (int k = 0; k < j; k++) {\n",
        "                // sum.add(sum, L[i][k] * L[j][k] * D[k][k]);\n",
        "                sum += L[i][k] * L[j][k] * D[k][k];\n",
        "            }\n",
        "\n",
        "            if (i == j) { // diagonal element\n",
        "                L[i][j] = 1;\n",
        "                // D[i][j].sub(A[i][i], sum);\n",
        "                D[i][j] = A[i][i] - sum;\n",
        "            }\n",
        "            \n",
        "            else { // off-diagonal element\n",
        "                type_t numer;\n",
        "                // numer.sub(A[i][j], sum);\n",
        "                numer = A[i][j] - sum;\n",
        "                L[i][j] = (type_t) numer / D[j][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "'''))\n",
        "\n",
        "\n",
        "(base / 'test.cpp').write_text(textwrap.dedent('''\\\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "\n",
        "    /* A is the symmetric, positive-definite matrix */\n",
        "    /* that we want to decompose */\n",
        "    type_t A[N][N] = { {4, 12, -16}, \n",
        "                    {12, 37, -43}, \n",
        "                    {-16, -43, 98}\n",
        "                };\n",
        "    \n",
        "    /* L is the lower triangular matrix */\n",
        "    type_t L[N][N] = {0, 0, 0, \n",
        "                    0, 0, 0, \n",
        "                    0, 0, 0};\n",
        "\n",
        "    /* D is the diagonal matrix */\n",
        "    type_t D[N][N] = {0, 0, 0, \n",
        "                    0, 0, 0, \n",
        "                    0, 0, 0};\n",
        "\n",
        "    cholesky(A, L, D);\n",
        "\n",
        "    printf(\"L:\\\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", L[i][j]);\n",
        "        }\n",
        "        printf(\"\\\\n\");\n",
        "    }\n",
        "    printf(\"D:\\\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", D[i][j]);\n",
        "        }\n",
        "        printf(\"\\\\n\");\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "'''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "XuOQ-i0YJ35L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuOQ-i0YJ35L",
        "outputId": "035ff52d-aaa7-48d6-9b72-1f8270615ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created inputs in inputs/cholesky_demo\n",
            "total 20\n",
            "drwxrwxr-x  2 ajh9498 ajh9498  114 Aug 27 11:12 .\n",
            "drwxrwxr-x 28 ajh9498 ajh9498 4096 Aug 27 11:12 ..\n",
            "-rw-rw-r--  1 ajh9498 ajh9498  245 Aug 27 11:14 config_cholesky_demo.yaml\n",
            "-rw-rw-r--  1 ajh9498 ajh9498  760 Aug 27 11:14 functions.cpp\n",
            "-rw-rw-r--  1 ajh9498 ajh9498  182 Aug 27 11:14 includes.h\n",
            "-rw-rw-r--  1 ajh9498 ajh9498  879 Aug 27 11:14 test.cpp\n",
            "\n",
            "Config:\n",
            "tcl: inputs/directives.tcl\n",
            "includes: inputs/cholesky_demo/includes.h\n",
            "orig_code: inputs/cholesky_demo/functions.cpp\n",
            "test_code: inputs/cholesky_demo/test.cpp\n",
            "top_function: cholesky\n",
            "hierarchical: true\n",
            "opt_constraint: area\n",
            "opt_constraint_tgt: 10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create yaml file\n",
        "\n",
        "import yaml\n",
        "\n",
        "# A minimal config based on the README description.\n",
        "config = {\n",
        "    'tcl': 'inputs/directives.tcl',\n",
        "    'includes': str(base / 'includes.h'),\n",
        "    'orig_code': str(base / 'functions.cpp'),\n",
        "    'test_code': str(base / 'test.cpp'),\n",
        "    'top_function': 'cholesky',\n",
        "    'hierarchical': True,\n",
        "    'opt_constraint': 'area',\n",
        "    'opt_constraint_tgt': 10000\n",
        "}\n",
        "(base / 'config_cholesky_demo.yaml').write_text(yaml.safe_dump(config, sort_keys=False))\n",
        "\n",
        "print('Created inputs in', base)\n",
        "!ls -la $base\n",
        "print('\\nConfig:')\n",
        "print((base / 'config_cholesky_demo.yaml').read_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4s7vwuKf74Mq",
      "metadata": {
        "id": "4s7vwuKf74Mq"
      },
      "source": [
        "## 6) Choose model and run C2HLSC\n",
        "Use `-h` output above to see accepted model names (e.g., OpenAI, Anthropic, and DeepSeek variants). Then pick an optimization target: `latency` or `throughput`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "run-c2hlsc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run-c2hlsc",
        "outputId": "18239f52-4bcd-4c47-d3c8-eb59212cdbe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running C2HLSC... this will call the LLM and may take a few minutes depending on your quota.\n",
            "Model:  o3-mini\n",
            "Running in mode:  standard Hierarchical:  True\n",
            "Optimization target:  latency\n",
            "{'cholesky': [], 'main': ['cholesky', 'printf', 'printf', 'printf', 'printf', 'printf', 'printf']}\n",
            "Building unit test for  cholesky\n",
            "clang -ggdb -g3 -O0 -fsanitize=address tmp_cholesky/cholesky_complete.c -o tmp_cholesky/to_debug\n",
            "{'cholesky': [(ArrayDecl(type=ArrayDecl(type=TypeDecl(declname='A',\n",
            "                                       quals=[\n",
            "                                             ],\n",
            "                                       align=None,\n",
            "                                       type=IdentifierType(names=['type_t'\n",
            "                                                                 ]\n",
            "                                                           )\n",
            "                                       ),\n",
            "                         dim=Constant(type='int',\n",
            "                                      value='3'\n",
            "                                      ),\n",
            "                         dim_quals=[\n",
            "                                   ]\n",
            "                         ),\n",
            "          dim=Constant(type='int',\n",
            "                       value='3'\n",
            "                       ),\n",
            "          dim_quals=[\n",
            "                    ]\n",
            "          ), 'A'), (ArrayDecl(type=ArrayDecl(type=TypeDecl(declname='L',\n",
            "                                       quals=[\n",
            "                                             ],\n",
            "                                       align=None,\n",
            "                                       type=IdentifierType(names=['type_t'\n",
            "                                                                 ]\n",
            "                                                           )\n",
            "                                       ),\n",
            "                         dim=Constant(type='int',\n",
            "                                      value='3'\n",
            "                                      ),\n",
            "                         dim_quals=[\n",
            "                                   ]\n",
            "                         ),\n",
            "          dim=Constant(type='int',\n",
            "                       value='3'\n",
            "                       ),\n",
            "          dim_quals=[\n",
            "                    ]\n",
            "          ), 'L'), (ArrayDecl(type=ArrayDecl(type=TypeDecl(declname='D',\n",
            "                                       quals=[\n",
            "                                             ],\n",
            "                                       align=None,\n",
            "                                       type=IdentifierType(names=['type_t'\n",
            "                                                                 ]\n",
            "                                                           )\n",
            "                                       ),\n",
            "                         dim=Constant(type='int',\n",
            "                                      value='3'\n",
            "                                      ),\n",
            "                         dim_quals=[\n",
            "                                   ]\n",
            "                         ),\n",
            "          dim=Constant(type='int',\n",
            "                       value='3'\n",
            "                       ),\n",
            "          dim_quals=[\n",
            "                    ]\n",
            "          ), 'D')], 'main': [(TypeDecl(declname=None,\n",
            "         quals=[\n",
            "               ],\n",
            "         align=None,\n",
            "         type=IdentifierType(names=['void'\n",
            "                                   ]\n",
            "                             )\n",
            "         ), None)]}\n",
            "OrderedDict([('A', <__main__.PointerData object at 0x7f809944eb10>), ('L', <__main__.PointerData object at 0x7f809944ebd0>), ('D', <__main__.PointerData object at 0x7f809944ecd0>)])\n",
            "model:  o3-mini\n",
            "Running catapult\n",
            "cholesky is correct, does not need any changes\n",
            "Last Catapult run:  Catapult\n",
            "System Prompt:  You are an expert in C and High-Level Synthesis (HLS), operating as an autonomous agent in a feedback-driven environment. \n",
            "Your task is to optimize synthesizable HLS code while preserving its original functionality. \n",
            "Modify only the specified functions for optimization without altering their logic. Optimization should be tailored for either throughput or latency as instructed.\n",
            "\n",
            "Optimization mechanisms include loop unrolling and pipelining. \n",
            "Use #pragma hls_unroll X to unroll loops with a factor of X, setting X to yes for full unrolling, which reduces latency at the cost of area and throughput. \n",
            "Use #pragma hls_pipeline_init_interval X to pipeline loops, where X defines the initiation interval and 0 disables pipelining. \n",
            "Pipelining increases throughput at the cost of latency. If no optimization is required, rewrite the original function without modifications.\n",
            "\n",
            "Output the modified code within ``` tags for automated processing. \n",
            "Expect iterative refinement based on feedback and adjust the output accordingly to improve efficiency while maintaining correctness.\n",
            "You will be iteratively asked to produce multiple solutions, explore different efforts to provide a good range of solutions.\n",
            "iteration  0\n",
            "Model:  o3-mini\n",
            "Prompt:  Update the cholesky function to optimize it for HLS targetting latency.\n",
            "        The function is \n",
            "```\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  for (int i = 0; i < 3; i++)\n",
            "  {\n",
            "    for (int j = 0; j <= i; j++)\n",
            "    {\n",
            "      type_t sum = 0;\n",
            "      for (int k = 0; k < j; k++)\n",
            "      {\n",
            "        sum += (L[i][k] * L[j][k]) * D[k][k];\n",
            "      }\n",
            "\n",
            "      if (i == j)\n",
            "      {\n",
            "        L[i][j] = 1;\n",
            "        D[i][j] = A[i][i] - sum;\n",
            "      }\n",
            "      else\n",
            "      {\n",
            "        type_t numer;\n",
            "        numer = A[i][j] - sum;\n",
            "        L[i][j] = ((type_t) numer) / D[j][j];\n",
            "      }\n",
            "    }\n",
            "\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "        The following child functions and includes will be provided to with the following signature, assume them present in the code:\n",
            "        \n",
            "```\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "#ifndef N\n",
            "#define N 3\n",
            "#endif\n",
            "\n",
            "#ifndef TYPE_T\n",
            "#define TYPE_T int\n",
            "#endif\n",
            "typedef TYPE_T type_t;\n",
            "\n",
            "void cholesky(type_t A[N][N], type_t L[N][N], type_t D[N][N]);\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "        You should not change the function signature. \n",
            "        The synthesis report from the base design with no optimizations is as follows: \n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                     180     440        446            0  0        ? \n",
            "\n",
            "  Design Total:                      180     440        446            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   30620.3          29733.4          27904.4        \n",
            "\n",
            "  Total Reg:           7826.8  (26%)    4402.3  (15%)    4402.3  (16%) \n",
            "\n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9C9gTMGSKDsZF9mhbEzUcrMcAyP4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```c\\nvoid cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\\n{\\n  for (int i = 0; i < 3; i++)\\n  {\\n    for (int j = 0; j <= i; j++)\\n    {\\n      #pragma hls_pipeline_init_interval 1\\n      type_t sum = 0;\\n      for (int k = 0; k < j; k++)\\n      {\\n        #pragma hls_unroll yes\\n        sum += (L[i][k] * L[j][k]) * D[k][k];\\n      }\\n      \\n      if (i == j)\\n      {\\n        L[i][j] = 1;\\n        D[i][j] = A[i][i] - sum;\\n      }\\n      else\\n      {\\n        type_t numer;\\n        numer = A[i][j] - sum;\\n        L[i][j] = ((type_t) numer) / D[j][j];\\n      }\\n    }\\n  }\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307712, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_c278fb013d', usage=CompletionUsage(completion_tokens=1385, prompt_tokens=720, total_tokens=2105, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1152, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "LLM RESPONSE:\n",
            "```c\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  for (int i = 0; i < 3; i++)\n",
            "  {\n",
            "    for (int j = 0; j <= i; j++)\n",
            "    {\n",
            "      #pragma hls_pipeline_init_interval 1\n",
            "      type_t sum = 0;\n",
            "      for (int k = 0; k < j; k++)\n",
            "      {\n",
            "        #pragma hls_unroll yes\n",
            "        sum += (L[i][k] * L[j][k]) * D[k][k];\n",
            "      }\n",
            "      \n",
            "      if (i == j)\n",
            "      {\n",
            "        L[i][j] = 1;\n",
            "        D[i][j] = A[i][i] - sum;\n",
            "      }\n",
            "      else\n",
            "      {\n",
            "        type_t numer;\n",
            "        numer = A[i][j] - sum;\n",
            "        L[i][j] = ((type_t) numer) / D[j][j];\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "Compiling the code\n",
            "The code is correct\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "The code is functionally correct, number of iterations: 1\n",
            "SYNTHESIS TOP: cholesky\n",
            "Running catapult\n",
            "The code is correct\n",
            "Last Catapult run:  Catapult_1\n",
            "System Prompt:  You are an expert in C and High-Level Synthesis (HLS), operating as an autonomous agent in a feedback-driven environment. \n",
            "Your task is to optimize synthesizable HLS code while preserving its original functionality. \n",
            "Modify only the specified functions for optimization without altering their logic. Optimization should be tailored for either throughput or latency as instructed.\n",
            "\n",
            "Optimization mechanisms include loop unrolling and pipelining. \n",
            "Use #pragma hls_unroll X to unroll loops with a factor of X, setting X to yes for full unrolling, which reduces latency at the cost of area and throughput. \n",
            "Use #pragma hls_pipeline_init_interval X to pipeline loops, where X defines the initiation interval and 0 disables pipelining. \n",
            "Pipelining increases throughput at the cost of latency. If no optimization is required, rewrite the original function without modifications.\n",
            "\n",
            "Output the modified code within ``` tags for automated processing. \n",
            "Expect iterative refinement based on feedback and adjust the output accordingly to improve efficiency while maintaining correctness.\n",
            "You will be iteratively asked to produce multiple solutions, explore different efforts to provide a good range of solutions.\n",
            "iteration  0\n",
            "Model:  o3-mini\n",
            "Prompt:  The synthesis report from the current design is as follows: \n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                     180     440        446            0  0        ? \n",
            "\n",
            "  Design Total:                      180     440        446            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   30620.3          29733.4          27904.4        \n",
            "\n",
            "  Total Reg:           7826.8  (26%)    4402.3  (15%)    4402.3  (16%) \n",
            " \n",
            "\n",
            "        The best area so far is: 27904.4 \n",
            "        The best latency so far is: 440.0 \n",
            "        The best throughput so far is: 446.0\n",
            "        Can you try improve your solution?\n",
            "        \n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9CAMtqzqi7nWECAhdsZBhWjFLJUm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```c\\nvoid cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\\n{\\n  for (int i = 0; i < 3; i++)\\n  {\\n    // The outer loop cannot be fully pipelined due to data dependencies between iterations.\\n    for (int j = 0; j <= i; j++)\\n    {\\n      // Pipeline the j-loop to reduce initiation interval and improve latency.\\n      #pragma hls_pipeline_init_interval 1\\n      type_t sum = 0;\\n      for (int k = 0; k < j; k++)\\n      {\\n        // Fully unroll the inner accumulation loop.\\n        #pragma hls_unroll yes\\n        sum += (L[i][k] * L[j][k]) * D[k][k];\\n      }\\n\\n      if (i == j)\\n      {\\n        L[i][j] = 1;\\n        D[i][j] = A[i][i] - sum;\\n      }\\n      else\\n      {\\n        type_t numer = A[i][j] - sum;\\n        L[i][j] = numer / D[j][j];\\n      }\\n    }\\n  }\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307754, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_c278fb013d', usage=CompletionUsage(completion_tokens=2186, prompt_tokens=1164, total_tokens=3350, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1920, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "LLM RESPONSE:\n",
            "```c\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  for (int i = 0; i < 3; i++)\n",
            "  {\n",
            "    // The outer loop cannot be fully pipelined due to data dependencies between iterations.\n",
            "    for (int j = 0; j <= i; j++)\n",
            "    {\n",
            "      // Pipeline the j-loop to reduce initiation interval and improve latency.\n",
            "      #pragma hls_pipeline_init_interval 1\n",
            "      type_t sum = 0;\n",
            "      for (int k = 0; k < j; k++)\n",
            "      {\n",
            "        // Fully unroll the inner accumulation loop.\n",
            "        #pragma hls_unroll yes\n",
            "        sum += (L[i][k] * L[j][k]) * D[k][k];\n",
            "      }\n",
            "\n",
            "      if (i == j)\n",
            "      {\n",
            "        L[i][j] = 1;\n",
            "        D[i][j] = A[i][i] - sum;\n",
            "      }\n",
            "      else\n",
            "      {\n",
            "        type_t numer = A[i][j] - sum;\n",
            "        L[i][j] = numer / D[j][j];\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "Compiling the code\n",
            "The code is correct\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "The code is functionally correct, number of iterations: 1\n",
            "SYNTHESIS TOP: cholesky\n",
            "Running catapult\n",
            "The code is correct\n",
            "Last Catapult run:  Catapult_2\n",
            "System Prompt:  You are an expert in C and High-Level Synthesis (HLS), operating as an autonomous agent in a feedback-driven environment. \n",
            "Your task is to optimize synthesizable HLS code while preserving its original functionality. \n",
            "Modify only the specified functions for optimization without altering their logic. Optimization should be tailored for either throughput or latency as instructed.\n",
            "\n",
            "Optimization mechanisms include loop unrolling and pipelining. \n",
            "Use #pragma hls_unroll X to unroll loops with a factor of X, setting X to yes for full unrolling, which reduces latency at the cost of area and throughput. \n",
            "Use #pragma hls_pipeline_init_interval X to pipeline loops, where X defines the initiation interval and 0 disables pipelining. \n",
            "Pipelining increases throughput at the cost of latency. If no optimization is required, rewrite the original function without modifications.\n",
            "\n",
            "Output the modified code within ``` tags for automated processing. \n",
            "Expect iterative refinement based on feedback and adjust the output accordingly to improve efficiency while maintaining correctness.\n",
            "You will be iteratively asked to produce multiple solutions, explore different efforts to provide a good range of solutions.\n",
            "iteration  0\n",
            "Model:  o3-mini\n",
            "Prompt:  The synthesis report from the current design is as follows: \n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                     180     440        446            0  0        ? \n",
            "\n",
            "  Design Total:                      180     440        446            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   30620.3          29733.4          27904.4        \n",
            "\n",
            "  Total Reg:           7826.8  (26%)    4402.3  (15%)    4402.3  (16%) \n",
            " \n",
            "\n",
            "        The best area so far is: 27904.4 \n",
            "        The best latency so far is: 440.0 \n",
            "        The best throughput so far is: 446.0\n",
            "        Can you try improve your solution?\n",
            "        \n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9CBDtvocBKKVanCRgxPgfSEwFNc1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```c\\nvoid cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\\n{\\n  // For a fixed-size (3x3) matrix, fully unrolling all loops minimizes latency by \\n  // computing all operations concurrently. This increases area but minimizes the critical path.\\n  #pragma hls_unroll yes\\n  for (int i = 0; i < 3; i++)\\n  {\\n    #pragma hls_unroll yes\\n    for (int j = 0; j <= i; j++)\\n    {\\n      type_t sum = 0;\\n      #pragma hls_unroll yes\\n      for (int k = 0; k < j; k++)\\n      {\\n        sum += (L[i][k] * L[j][k]) * D[k][k];\\n      }\\n\\n      if (i == j)\\n      {\\n        L[i][j] = 1;\\n        D[i][j] = A[i][i] - sum;\\n      }\\n      else\\n      {\\n        type_t numer = A[i][j] - sum;\\n        L[i][j] = numer / D[j][j];\\n      }\\n    }\\n  }\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307807, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_c278fb013d', usage=CompletionUsage(completion_tokens=1933, prompt_tokens=1641, total_tokens=3574, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1664, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1152)))\n",
            "LLM RESPONSE:\n",
            "```c\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  // For a fixed-size (3x3) matrix, fully unrolling all loops minimizes latency by \n",
            "  // computing all operations concurrently. This increases area but minimizes the critical path.\n",
            "  #pragma hls_unroll yes\n",
            "  for (int i = 0; i < 3; i++)\n",
            "  {\n",
            "    #pragma hls_unroll yes\n",
            "    for (int j = 0; j <= i; j++)\n",
            "    {\n",
            "      type_t sum = 0;\n",
            "      #pragma hls_unroll yes\n",
            "      for (int k = 0; k < j; k++)\n",
            "      {\n",
            "        sum += (L[i][k] * L[j][k]) * D[k][k];\n",
            "      }\n",
            "\n",
            "      if (i == j)\n",
            "      {\n",
            "        L[i][j] = 1;\n",
            "        D[i][j] = A[i][i] - sum;\n",
            "      }\n",
            "      else\n",
            "      {\n",
            "        type_t numer = A[i][j] - sum;\n",
            "        L[i][j] = numer / D[j][j];\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "Compiling the code\n",
            "The code is correct\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "The code is functionally correct, number of iterations: 1\n",
            "SYNTHESIS TOP: cholesky\n",
            "Running catapult\n",
            "The code is correct\n",
            "Last Catapult run:  Catapult_3\n",
            "System Prompt:  You are an expert in C and High-Level Synthesis (HLS), operating as an autonomous agent in a feedback-driven environment. \n",
            "Your task is to optimize synthesizable HLS code while preserving its original functionality. \n",
            "Modify only the specified functions for optimization without altering their logic. Optimization should be tailored for either throughput or latency as instructed.\n",
            "\n",
            "Optimization mechanisms include loop unrolling and pipelining. \n",
            "Use #pragma hls_unroll X to unroll loops with a factor of X, setting X to yes for full unrolling, which reduces latency at the cost of area and throughput. \n",
            "Use #pragma hls_pipeline_init_interval X to pipeline loops, where X defines the initiation interval and 0 disables pipelining. \n",
            "Pipelining increases throughput at the cost of latency. If no optimization is required, rewrite the original function without modifications.\n",
            "\n",
            "Output the modified code within ``` tags for automated processing. \n",
            "Expect iterative refinement based on feedback and adjust the output accordingly to improve efficiency while maintaining correctness.\n",
            "You will be iteratively asked to produce multiple solutions, explore different efforts to provide a good range of solutions.\n",
            "iteration  0\n",
            "Model:  o3-mini\n",
            "Prompt:  The synthesis report from the current design is as follows: \n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                      27       8         10            0  0          \n",
            "\n",
            "  Design Total:                       27       8         10            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   26618.0          72683.7          26431.3        \n",
            "\n",
            "  Total Reg:           6945.8  (26%)    3340.8   (5%)    3340.8  (13%) \n",
            " \n",
            "\n",
            "        The best area so far is: 26431.3 \n",
            "        The best latency so far is: 8.0 \n",
            "        The best throughput so far is: 10.0\n",
            "        Can you try improve your solution?\n",
            "        \n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9CBw6ZJAMJ6304XpWJc799TZxae3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```c\\nvoid cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\\n{\\n  // For a 3x3 matrix, we can completely eliminate loop overhead\\n  // by writing out the operations explicitly. This fully\\n  // combinational implementation minimizes latency.\\n  \\n  // Row 0\\n  L[0][0] = 1;\\n  D[0][0] = A[0][0];\\n  \\n  // Row 1\\n  // Compute L[1][0]\\n  L[1][0] = A[1][0] / D[0][0];\\n  // Diagonal element\\n  L[1][1] = 1;\\n  D[1][1] = A[1][1] - (L[1][0] * L[1][0] * D[0][0]);\\n  \\n  // Row 2\\n  // Compute L[2][0]\\n  L[2][0] = A[2][0] / D[0][0];\\n  // Compute L[2][1]\\n  L[2][1] = (A[2][1] - (L[2][0] * L[1][0] * D[0][0])) / D[1][1];\\n  // Diagonal element\\n  L[2][2] = 1;\\n  D[2][2] = A[2][2] - ((L[2][0] * L[2][0] * D[0][0]) +\\n                        (L[2][1] * L[2][1] * D[1][1]));\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307852, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_c278fb013d', usage=CompletionUsage(completion_tokens=3380, prompt_tokens=2120, total_tokens=5500, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=3008, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1536)))\n",
            "LLM RESPONSE:\n",
            "```c\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  // For a 3x3 matrix, we can completely eliminate loop overhead\n",
            "  // by writing out the operations explicitly. This fully\n",
            "  // combinational implementation minimizes latency.\n",
            "  \n",
            "  // Row 0\n",
            "  L[0][0] = 1;\n",
            "  D[0][0] = A[0][0];\n",
            "  \n",
            "  // Row 1\n",
            "  // Compute L[1][0]\n",
            "  L[1][0] = A[1][0] / D[0][0];\n",
            "  // Diagonal element\n",
            "  L[1][1] = 1;\n",
            "  D[1][1] = A[1][1] - (L[1][0] * L[1][0] * D[0][0]);\n",
            "  \n",
            "  // Row 2\n",
            "  // Compute L[2][0]\n",
            "  L[2][0] = A[2][0] / D[0][0];\n",
            "  // Compute L[2][1]\n",
            "  L[2][1] = (A[2][1] - (L[2][0] * L[1][0] * D[0][0])) / D[1][1];\n",
            "  // Diagonal element\n",
            "  L[2][2] = 1;\n",
            "  D[2][2] = A[2][2] - ((L[2][0] * L[2][0] * D[0][0]) +\n",
            "                        (L[2][1] * L[2][1] * D[1][1]));\n",
            "}\n",
            "```\n",
            "Compiling the code\n",
            "The code is correct\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "The code is functionally correct, number of iterations: 1\n",
            "SYNTHESIS TOP: cholesky\n",
            "Running catapult\n",
            "The code is correct\n",
            "Last Catapult run:  Catapult_4\n",
            "System Prompt:  You are an expert in C and High-Level Synthesis (HLS), operating as an autonomous agent in a feedback-driven environment. \n",
            "Your task is to optimize synthesizable HLS code while preserving its original functionality. \n",
            "Modify only the specified functions for optimization without altering their logic. Optimization should be tailored for either throughput or latency as instructed.\n",
            "\n",
            "Optimization mechanisms include loop unrolling and pipelining. \n",
            "Use #pragma hls_unroll X to unroll loops with a factor of X, setting X to yes for full unrolling, which reduces latency at the cost of area and throughput. \n",
            "Use #pragma hls_pipeline_init_interval X to pipeline loops, where X defines the initiation interval and 0 disables pipelining. \n",
            "Pipelining increases throughput at the cost of latency. If no optimization is required, rewrite the original function without modifications.\n",
            "\n",
            "Output the modified code within ``` tags for automated processing. \n",
            "Expect iterative refinement based on feedback and adjust the output accordingly to improve efficiency while maintaining correctness.\n",
            "You will be iteratively asked to produce multiple solutions, explore different efforts to provide a good range of solutions.\n",
            "iteration  0\n",
            "Model:  o3-mini\n",
            "Prompt:  The synthesis report from the current design is as follows: \n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                      25       9         10            0  0          \n",
            "\n",
            "  Design Total:                       25       9         10            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   25392.2          75657.8          26537.2        \n",
            "\n",
            "  Total Reg:           5720.1  (23%)    3340.8   (4%)    3340.8  (13%) \n",
            " \n",
            "\n",
            "        The best area so far is: 26431.3 \n",
            "        The best latency so far is: 8.0 \n",
            "        The best throughput so far is: 10.0\n",
            "        Can you try improve your solution?\n",
            "        \n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9CCulzzzP2k9n4kEczq7BTAdXhuS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```c\\nvoid cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\\n{\\n  // Fully unroll all loops to produce a combinational datapath for a 3x3 matrix.\\n  // This version targets minimal latency (as low as 8 cycles) by completely eliminating\\n  // loop overhead. Note that full unrolling increases area but minimizes latency.\\n  #pragma hls_unroll yes\\n  for (int i = 0; i < 3; i++) {\\n    #pragma hls_unroll yes\\n    for (int j = 0; j <= i; j++) {\\n      type_t sum = 0;\\n      \\n      #pragma hls_unroll yes\\n      for (int k = 0; k < j; k++) {\\n        sum += (L[i][k] * L[j][k]) * D[k][k];\\n      }\\n      \\n      if(i == j) {\\n        L[i][j] = 1;\\n        D[i][j] = A[i][i] - sum;\\n      }\\n      else {\\n        type_t numer = A[i][j] - sum;\\n        L[i][j] = numer / D[j][j];\\n      }\\n    }\\n  }\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307912, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_c278fb013d', usage=CompletionUsage(completion_tokens=2587, prompt_tokens=2702, total_tokens=5289, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2304, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=2048)))\n",
            "LLM RESPONSE:\n",
            "```c\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  // Fully unroll all loops to produce a combinational datapath for a 3x3 matrix.\n",
            "  // This version targets minimal latency (as low as 8 cycles) by completely eliminating\n",
            "  // loop overhead. Note that full unrolling increases area but minimizes latency.\n",
            "  #pragma hls_unroll yes\n",
            "  for (int i = 0; i < 3; i++) {\n",
            "    #pragma hls_unroll yes\n",
            "    for (int j = 0; j <= i; j++) {\n",
            "      type_t sum = 0;\n",
            "      \n",
            "      #pragma hls_unroll yes\n",
            "      for (int k = 0; k < j; k++) {\n",
            "        sum += (L[i][k] * L[j][k]) * D[k][k];\n",
            "      }\n",
            "      \n",
            "      if(i == j) {\n",
            "        L[i][j] = 1;\n",
            "        D[i][j] = A[i][i] - sum;\n",
            "      }\n",
            "      else {\n",
            "        type_t numer = A[i][j] - sum;\n",
            "        L[i][j] = numer / D[j][j];\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "Compiling the code\n",
            "The code is correct\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "b'4 12 -16 12 37 -43 -16 -43 98 \\n1 0 0 3 1 0 -4 5 1 \\n4 0 0 0 1 0 0 0 9 \\n'\n",
            "The code is functionally correct, number of iterations: 1\n",
            "SYNTHESIS TOP: cholesky\n",
            "Running catapult\n",
            "The code is correct\n",
            "Last Catapult run:  Catapult_5\n",
            "Best solution found: Catapult_3\n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                      27       8         10            0  0          \n",
            "\n",
            "  Design Total:                       27       8         10            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   26618.0          72683.7          26431.3        \n",
            "\n",
            "  Total Reg:           6945.8  (26%)    3340.8   (5%)    3340.8  (13%) \n",
            "\n",
            "System Prompt:  \n",
            "You are an HLS Optimization Agent tasked with optimizing a C application accelerated using High-Level Synthesis (HLS). \n",
            "You are part of an automated agentic flow, please reply following the instructed format.\n",
            "Your goal is to find the best combination of function options that minimizes latency while keeping the total area as close as possible to a target value. \n",
            "At every iteration you have three options:\n",
            "1. Synthesize a new configuration to evaluate its latency throughput and area.\n",
            "If you select this option you should replay in the following format:\n",
            "\"synthesis: <function_name_1> <option_index>, <function_name_2> <option_index>, ..., <function_name_n> <option_index>\" for each function in the application.\n",
            "I will run the synthesis and provide you with the results.\n",
            "2. See one or more function options.\n",
            "If you select this option you should reply with the following format:\n",
            "\"inspect: <function_name_1> <option_index>, <function_name_2> <option_index>, ..., <function_name_n> <option_index>\"\n",
            "3. Run the a python script to solve an optimization problem using the google OR-Tools library.\n",
            "If you select this option you should reply with the following format:\n",
            "\"python: '''<python_scipt_to_run>'''\"\n",
            "I will run the script and provide you with the results.\n",
            "4. Run gprof on the applacation to profile the code.\n",
            "If you select this option you should reply with the following format:\n",
            "\"profile\"\n",
            "I will run the gprof and provide you with the results.\n",
            "5. Accept a solution and provide the final configuration.\n",
            "If you select this option you should reply with the following format:\n",
            "\"solution: <function_name_1> <option_index>, <function_name_2> <option_index>, ..., <function_name_n> <option_index>\"\n",
            "\n",
            "Only reply with one of the five options following the format provided.\n",
            "\n",
            "Prompt:  \n",
            "This is the call graph for the application at hand:\n",
            "{'cholesky': [], 'main': ['cholesky', 'printf', 'printf', 'printf', 'printf', 'printf', 'printf']}\n",
            "\n",
            "The application has the following functions with their respective options:\n",
            "Option for cholesky -  area: 27904.4, latency: 440.0, throughput: 446.0\n",
            "Option for cholesky -  area: 27904.4, latency: 440.0, throughput: 446.0\n",
            "Option for cholesky -  area: 26431.3, latency: 8.0, throughput: 10.0\n",
            "Option for cholesky -  area: 26537.2, latency: 9.0, throughput: 10.0\n",
            "Option for cholesky -  area: 26431.3, latency: 8.0, throughput: 10.0\n",
            "\n",
            "\n",
            "Use the function names as provided, indexing the options starting from 0\n",
            "The throughput is expressed in period, the lower the better.\n",
            "\n",
            "The values reported for a function are obtained synthesizing the function in isolation, selecting the best latency from the child functions.\n",
            "This means that the child functions are included in the function synthesis. Selecting a different option will affect the final outcome of the parent function.\n",
            "Different options use different unrolling and pipelining factors. \n",
            "\n",
            "The goal is to minimize the latency while keeping the total area as close as possible to 10000.\n",
            "\n",
            "Provide your first request:\n",
            "\n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9CDfcdN3MeBXhAhV5HphmrFJ9jcy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='synthesis: cholesky 2', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307959, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_e20469f047', usage=CompletionUsage(completion_tokens=789, prompt_tokens=714, total_tokens=1503, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=768, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "synthesis: cholesky 2\n",
            "func:  cholesky 2\n",
            "func:  cholesky 2\n",
            "Last Catapult run:  Catapult_6\n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                      27       8         10            0  0          \n",
            "\n",
            "  Design Total:                       27       8         10            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   26618.0          72683.7          26431.3        \n",
            "\n",
            "  Total Reg:           6945.8  (26%)    3340.8   (5%)    3340.8  (13%) \n",
            "\n",
            "Prompt:  The synthesis report from last configuration is as follows: \n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments \n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                      27       8         10            0  0          \n",
            "\n",
            "  Design Total:                       27       8         10            0  0          \n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment \n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   26618.0          72683.7          26431.3        \n",
            "\n",
            "  Total Reg:           6945.8  (26%)    3340.8   (5%)    3340.8  (13%) \n",
            " \n",
            "\n",
            "LLM RAW RESPONSE:  ChatCompletion(id='chatcmpl-C9CEBVMStiAtckrCKzIBxcxfXKEgh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='solution: cholesky 2', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756307991, model='o3-mini-2025-01-31', object='chat.completion', service_tier='default', system_fingerprint='fp_e20469f047', usage=CompletionUsage(completion_tokens=1300, prompt_tokens=894, total_tokens=2194, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1280, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "solution: cholesky 2\n",
            "DONE!\n",
            "Logging results in  outputs_cholesky_o3-mini_2/cholesky.log\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run C2HLSC with chosen LLM model and optimization target\n",
        "\n",
        "MODEL = 'o3-mini' # change to a supported model printed by -h, e.g., 'anthropic:claude-3-5-sonnet'\n",
        "OPT_TARGET = 'latency' # or 'throughput'\n",
        "CFG = (base / 'config_cholesky_demo.yaml')\n",
        "\n",
        "print('Running C2HLSC... this will call the LLM and may take a few minutes depending on your quota.')\n",
        "!python3.11 src/c2hlsc.py $CFG --model $MODEL --opt_target $OPT_TARGET || true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uanUHsJZX1OM",
      "metadata": {
        "id": "uanUHsJZX1OM"
      },
      "source": [
        "## 7) Inspect outputs\n",
        "After running C2HLSC, you should find an `outputs_{kernel}_{model}_{run}/` directory in the repo containing:\n",
        "\n",
        "- Refactored C code &rarr; `{kernel}_result.c`\n",
        "\n",
        "- Results log &rarr; `{kernel}.log`\n",
        "\n",
        "Let’s preview the latest results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inspect-results",
      "metadata": {
        "id": "inspect-results"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "KERNEL = 'cholesky' # the top function name used above\n",
        "MODEL = 'o3-mini' # ensure this matches the model used above\n",
        "RUN = '1' # the run number, adjust if needed\n",
        "\n",
        "# Point to your latest run directory\n",
        "run_dir = Path(f'outputs_{KERNEL}_{MODEL}_{RUN}')\n",
        "\n",
        "# Files to preview\n",
        "c_file = run_dir / f'{KERNEL}_result.c'\n",
        "log_file = run_dir / f'{KERNEL}.log'\n",
        "\n",
        "# Helper function to preview a file\n",
        "def preview(path):\n",
        "    print(f\"\\n=== {path.name} ===\")\n",
        "    try:\n",
        "        with open(path) as f:\n",
        "            for line in f:\n",
        "                print(line.rstrip())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"[Missing: {path}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cb7fdcaf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== cholesky_result.c ===\n",
            "\n",
            "#include \"../include/ac_float.h\"\n",
            "#include \"../include/ac_fixed.h\"\n",
            "#include <stdint.h>\n",
            "\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "#ifndef N\n",
            "#define N 3\n",
            "#endif\n",
            "\n",
            "#ifndef TYPE_T\n",
            "#define TYPE_T int\n",
            "#endif\n",
            "typedef TYPE_T type_t;\n",
            "\n",
            "void cholesky(type_t A[N][N], type_t L[N][N], type_t D[N][N]);\n",
            "\n",
            "\n",
            "\n",
            "void cholesky(type_t A[3][3], type_t L[3][3], type_t D[3][3])\n",
            "{\n",
            "  // For a fixed-size (3x3) matrix, fully unrolling all loops minimizes latency by\n",
            "  // computing all operations concurrently. This increases area but minimizes the critical path.\n",
            "  #pragma hls_unroll yes\n",
            "  for (int i = 0; i < 3; i++)\n",
            "  {\n",
            "    #pragma hls_unroll yes\n",
            "    for (int j = 0; j <= i; j++)\n",
            "    {\n",
            "      type_t sum = 0;\n",
            "      #pragma hls_unroll yes\n",
            "      for (int k = 0; k < j; k++)\n",
            "      {\n",
            "        sum += (L[i][k] * L[j][k]) * D[k][k];\n",
            "      }\n",
            "\n",
            "      if (i == j)\n",
            "      {\n",
            "        L[i][j] = 1;\n",
            "        D[i][j] = A[i][i] - sum;\n",
            "      }\n",
            "      else\n",
            "      {\n",
            "        type_t numer = A[i][j] - sum;\n",
            "        L[i][j] = numer / D[j][j];\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "int main()\n",
            "{\n",
            "  unsigned int A[] = {4, 12, 4294967280, 12, 37, 4294967253, 4294967280, 4294967253, 98};\n",
            "  unsigned int L[] = {0, 0, 0, 0, 0, 0, 0, 0, 0};\n",
            "  unsigned int D[] = {0, 0, 0, 0, 0, 0, 0, 0, 0};\n",
            "  cholesky((type_t (*)[3]) A, (type_t (*)[3]) L, (type_t (*)[3]) D);\n",
            "  for (int _i = 0; _i < 9; _i++)\n",
            "  {\n",
            "    printf(\"%d \", A[_i]);\n",
            "  }\n",
            "\n",
            "  printf(\"\\n\");\n",
            "  for (int _i = 0; _i < 9; _i++)\n",
            "  {\n",
            "    printf(\"%d \", L[_i]);\n",
            "  }\n",
            "\n",
            "  printf(\"\\n\");\n",
            "  for (int _i = 0; _i < 9; _i++)\n",
            "  {\n",
            "    printf(\"%d \", D[_i]);\n",
            "  }\n",
            "\n",
            "  printf(\"\\n\");\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the refactored C\n",
        "\n",
        "preview(c_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "259652a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== cholesky.log ===\n",
            "o3-mini runs: 7\n",
            "o3-mini input tokens: 9955\n",
            "o3-mini output tokens: 13560\n",
            "# of functions: 1\n",
            "HLS runs: 7\n",
            "Compile runs: 10\n",
            "Time for c2hlsc:  270255\n",
            "Time for agent:  43588\n",
            "Agent sequence:  ['synthesis: cholesky 2', 'solution: cholesky 2']\n",
            "Agent synthesis calls:  1\n",
            "Agent python calls:  0\n",
            "Agent profile calls:  0\n",
            "Agent inspect calls:  0\n",
            "Agent solution calls:  1\n",
            "Seconds lost due to API down:  0\n",
            "  Process        Real Operation(s) count Latency Throughput Reset Length II Comments\n",
            "\n",
            "  -------------- ----------------------- ------- ---------- ------------ -- --------\n",
            "\n",
            "  /cholesky/core                      27       8         10            0  0\n",
            "\n",
            "  Design Total:                       27       8         10            0  0\n",
            "\n",
            "                     Post-Scheduling    Post-DP & FSM  Post-Assignment\n",
            "\n",
            "  ----------------- ---------------- ---------------- ----------------\n",
            "\n",
            "  Total Area Score:   26618.0          72683.7          26431.3\n",
            "\n",
            "  Total Reg:           6945.8  (26%)    3340.8   (5%)    3340.8  (13%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the log\n",
        "\n",
        "preview(log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nmtCTYZt74Mr",
      "metadata": {
        "id": "nmtCTYZt74Mr"
      },
      "source": [
        "## 8) Validate with `g++` (software test)\n",
        "We’ll compile and execute the transformed C to sanity-check functional correctness outside of HLS. \n",
        "\n",
        "Because the transformed file contains a `main()`, we compile and run it directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gcc-validate",
      "metadata": {
        "id": "gcc-validate"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling outputs_cholesky_o3-mini_2/cholesky_result.c...\n",
            "\n",
            "Running outputs_cholesky_o3-mini_2/cholesky.exe...\n",
            "\n",
            "4 12 -16 12 37 -43 -16 -43 98 \n",
            "1 0 0 3 1 0 -4 5 1 \n",
            "4 0 0 0 1 0 0 0 9 \n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "KERNEL = 'cholesky' # the top function name used above\n",
        "MODEL = 'o3-mini' # ensure this matches the model used above\n",
        "RUN = '1' # the run number, adjust if needed\n",
        "\n",
        "# Point to your latest run directory\n",
        "run_dir = Path(f'outputs_{KERNEL}_{MODEL}_{RUN}')\n",
        "\n",
        "c_file = run_dir / f'{KERNEL}_result.c'\n",
        "exe_file = run_dir / f'{KERNEL}.exe'\n",
        "\n",
        "# Compile\n",
        "print(f'Compiling {c_file}...')\n",
        "subprocess.run(['g++', str(c_file), '-o', str(exe_file)], check=True)\n",
        "\n",
        "# Run\n",
        "print(f'\\nRunning {exe_file}...\\n')\n",
        "subprocess.run([str(exe_file)])\n",
        "\n",
        "print('\\nDone.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
